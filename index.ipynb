{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = [\n",
    "    '/data/Pat1/CT_scan/DICOM/PA000001/ST000001/SE000005',\n",
    "    '/data/Pat2/CT_scan/DICOM/PA000001/ST000001/SE000002',\n",
    "    '/data/Pat3/CT_scan/DICOM/PA000001/ST000001/SE000002',\n",
    "    '/data/Pat4/CT_scan/DICOM/PA000001/ST000001/SE000001',\n",
    "    '/data/Pat5/CT_scan/CAROL_JARVIS_PARKER_DAVID_08_01_2020/Jarvis, Carol KneeR/DICOM/PA000001/ST000001/SE000001',\n",
    "    '/data/Pat6/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat7/CT_scan/DICOM/PA000001/ST000001/SE000003/',\n",
    "    '/data/Pat8/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat9/CT_scan/PA000001/ST000001/SE000002/',\n",
    "    '/data/Pat10/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat11/CT_scan/Maloney,myree/DICOM/PA000001/ST000001/SE000003/',\n",
    "    '/data/Pat12/CT_scan/STANTON^PETER^^Mr^_CT_22256795E1_360 KS Protocol v9 PreOp Knee(Adult)/Series 003/',\n",
    "    '/data/Pat13/CT_scan/Wilson, Anthony Knee/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat14/CT_scan/TIJS^THEO^^Mr^_CT_20933520E1_CT Knee - Non Contrast 1112018 (Right)/Series 001/',\n",
    "    '/data/Pat15/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat16/CT_scan/MARRIOTT^MERLE^^Mrs^_CT_22464345E1_360 KS Protocol v8 Pre Knee(Adult)/Series 002/',\n",
    "    '/data/Pat17/CT_scan/PA000001/ST000001/SE000002/',\n",
    "    '/data/Pat18/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat19/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/Pat20/CT_scan/DICOM/PA000001/ST000001/SE000001/',\n",
    "    '/data/case01/SE000001/',\n",
    "    '/data/case02/SE000001/',\n",
    "    '/data/case03/SE000001/',\n",
    "    '/data/case04/SE000003/',\n",
    "    '/data/case05/SE000001/',\n",
    "    '/data/case06/SE000002/',\n",
    "    '/data/case07/SE000001/',\n",
    "    '/data/case08/SE000005/',\n",
    "    '/data/case09/SE000004/',\n",
    "    '/data/case10/SE000001/',\n",
    "    '/data/case11/SE000001/',\n",
    "    '/data/case12/SE000001/',\n",
    "    '/data/case13/SE000004/',\n",
    "    '/data/case14/SE000001/',\n",
    "    '/data/case15/SE000001/',\n",
    "    '/data/case16/SE000003/',\n",
    "    '/data/case17/SE000001/',\n",
    "    '/data/case18/SE000002/',\n",
    "    '/data/case19/SE000003/',\n",
    "    '/data/case20/SE000001/',\n",
    "]\n",
    "\n",
    "paths_csv = [\n",
    "    '/data/Pat1/POD_JR_9060K_Landmarks_femur.csv',\n",
    "    '/data/Pat2/EVA_JR_9035K_Landmarks_femur.csv',\n",
    "    '/data/Pat3/ROL_KH_9128K_Landmarks_femur.csv',\n",
    "    '/data/Pat4/BRO_DL_9146K_Landmarks_femur.csv',\n",
    "    '/data/Pat5/JAR_DP_9043K_Landmarks_femur.csv',\n",
    "    '/data/Pat6/TOW_PY_9046K_Landmarks_femur.csv',\n",
    "    '/data/Pat7/GIL_DP_9140K_Landmarks_femur.csv',\n",
    "    '/data/Pat8/PRI_ML_9034K_Landmarks_femur.csv',\n",
    "    '/data/Pat9/MCD_DL_9103K_Landmarks_femur.csv',\n",
    "    '/data/Pat10/JAC_ML_8976K_Landmarks_femur.csv',\n",
    "    '/data/Pat11/MAL_ML_8972K_Landmarks_femur.csv',\n",
    "    '/data/Pat12/STA_AS_8743K_Landmarks_femur.csv',\n",
    "    '/data/Pat13/WIL_ML_8944K_Landmarks_femur.csv',\n",
    "    '/data/Pat14/Landmarks_femur.csv',\n",
    "    '/data/Pat15/HIG_DP_9018K_Landmarks_femur.csv',\n",
    "    '/data/Pat16/MAR_JB_8722K_Landmarks_femur.csv',\n",
    "    '/data/Pat17/STE_DL_9085K_Landmarks_femur.csv',\n",
    "    '/data/Pat18/GRE_DP_9095K_Landmarks_femur.csv',\n",
    "    '/data/Pat19/GRE_DP_9096K_Landmarks_femur.csv',\n",
    "    '/data/Pat20/MUR_BF_9127K_Landmarks_femur.csv',\n",
    "    '/data/case01/BEE_DP_9391K_Landmarks_femur.csv',\n",
    "    '/data/case02/LIN_GK_9469K_Landmarks_femur.csv',\n",
    "    '/data/case03/MAR_DP_9480K_Landmarks_femur.csv',\n",
    "    '/data/case04/STE_DP_9504K_Landmarks_femur.csv',\n",
    "    '/data/case05/LES_JR_9281K_Landmarks_femur.csv',\n",
    "    '/data/case06/FLO_ML_9439K_Landmarks_femur.csv',\n",
    "    '/data/case07/SAR_JR_9460K_Landmarks_femur.csv',\n",
    "    '/data/case08/POD_JR_9060K_Landmarks_femur.csv',\n",
    "    '/data/case09/NIV_JR_9383K_Landmarks_femur.csv',\n",
    "    '/data/case10/SMI_GK_9360K_Landmarks_femur.csv',\n",
    "    '/data/case11/GRO_GK_9370K_Landmarks_femur.csv',\n",
    "    '/data/case12/GAL_GK_9437K_Landmarks_femur.csv',\n",
    "    '/data/case13/SIN_DP_8982K_Landmarks_femur.csv',\n",
    "    '/data/case14/HAR_GK_8977K_Landmarks_femur.csv',\n",
    "    '/data/case15/CUT_GK_9031K_Landmarks_femur.csv',\n",
    "    '/data/case16/AST_JR_9253K_Landmarks_femur.csv',\n",
    "    '/data/case17/CHE_DP_9065K_Landmarks_femur.csv',\n",
    "    '/data/case18/ROS_ML_9251K_Landmarks_femur.csv',\n",
    "    '/data/case19/WON_JR_9033K_Landmarks_femur.csv',\n",
    "    '/data/case20/ORT_ML_9286K_Landmarks_femur.csv',\n",
    "]\n",
    "\n",
    "output_path = \"/code/\"\n",
    "\n",
    "unknown_landmarks = [\n",
    "    'PCLOrigin',\n",
    "    'lateralCondyle',\n",
    "    'medialCondyle',\n",
    "    'medialSulcus',\n",
    "    'whitesideReference'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from glob import glob\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_scan(path):\n",
    "    \n",
    "    # load the DICOM files\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(path):\n",
    "        for filename in fileList:\n",
    "            if \".zip\" not in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "    files = []\n",
    "    for fname in lstFilesDCM:\n",
    "        files.append(pydicom.dcmread(fname))\n",
    "    slices = []\n",
    "    skipcount = 0\n",
    "    for f in files:\n",
    "        if hasattr(f, 'SliceLocation'):\n",
    "            slices.append(f)\n",
    "        else:\n",
    "            skipcount = skipcount + 1\n",
    "    slices = sorted(slices, key=lambda s: s.SliceLocation)\n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(slices):\n",
    "    # create 3D array\n",
    "    img_shape = list(slices[0].pixel_array.shape)\n",
    "    img_shape.append(len(slices))\n",
    "    img3d = np.zeros(img_shape)\n",
    "\n",
    "    for i, s in enumerate(slices):\n",
    "        img2d = s.pixel_array\n",
    "        img3d[:, :, i] = img2d\n",
    "    img3d[img3d == -2000] = 0\n",
    "    return img3d\n",
    "\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = map(float,(list(scan[0].PixelSpacing))+ [scan[0].SliceThickness] )\n",
    "\n",
    "    spacing = np.array(list(spacing))\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "def convert_global_aix_to_net_pos(point, spacing, origin):\n",
    "    point['x'] = (point['x'] - origin[0]) / spacing[0]\n",
    "    point['y'] = (point['y'] - origin[1]) / spacing[1]\n",
    "    point['z'] = (point['z'] - origin[2]) / spacing[2]\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_into_numpy(pat_id):\n",
    "    # pat_id = 0\n",
    "    path_csv = paths_csv[pat_id]\n",
    "    data_path = paths[pat_id]\n",
    "    g = glob(data_path + '/*')\n",
    "    print(\"data_path:\", data_path)\n",
    "    print(\"path_csv:\", path_csv)\n",
    "\n",
    "    slices = load_scan(data_path)\n",
    "    img3d = get_pixels_hu(slices)\n",
    "    imgs_after_resamp, spacing = resample(img3d, slices, [1,1,1])\n",
    "    imgs_after_resamp = imgs_after_resamp.transpose(1,0,2)\n",
    "\n",
    "    data = pd.read_csv(path_csv, names=[\"Name\", \"x\", \"y\", \"z\"])\n",
    "    data = convert_global_aix_to_net_pos(data, spacing, slices[0].ImagePositionPatient)\n",
    "\n",
    "    np.save(output_path + 'images/' + \"%d.npy\" % (pat_id), imgs_after_resamp)\n",
    "    np.save(output_path + 'label/' + \"%d.npy\" % (pat_id), np.array(data.values))\n",
    "    print(' ')\n",
    "\n",
    "#     cude_size = 2\n",
    "\n",
    "#     cube = 60\n",
    "#     for index, row in data.iterrows():\n",
    "#         if row['Name'] in unknown_landmarks:\n",
    "#             mark_img = np.zeros(imgs_after_resamp.shape)\n",
    "#             for i in range(-cude_size, cude_size):\n",
    "#                 for j in range(-cude_size, cude_size):\n",
    "#                     for k in range(-cude_size, cude_size):\n",
    "#                         mark_img[i+int(row['x']), j+int(row['y']), k+int(row['z'])] = 5200\n",
    "#             print(row['x'], row['y'], row['z'])\n",
    "#             rad = random.randint(30,cube)\n",
    "#             print(\n",
    "#                 int(row['x']) - cube - rad, cube + int(row['x']) - rad,\n",
    "#                 int(row['y']) - cube - rad, cube + int(row['y']) - rad,\n",
    "#                 int(row['z']) - cube - rad, cube + int(row['z']) - rad)\n",
    "\n",
    "#             print(row['Name'])\n",
    "#             print(rad)\n",
    "#             new_mark = mark_img[\n",
    "#                 int(row['x']) - cube - rad: cube + int(row['x']) - rad,\n",
    "#                 int(row['y']) - cube - rad: cube + int(row['y']) - rad,\n",
    "#                 int(row['z']) - cube - rad: cube + int(row['z']) - rad\n",
    "#             ]\n",
    "\n",
    "#             new_shape = imgs_after_resamp[\n",
    "#                 int(row['x']) - cube - rad: cube + int(row['x']) - rad,\n",
    "#                 int(row['y']) - cube - rad: cube + int(row['y']) - rad,\n",
    "#                 int(row['z']) - cube - rad: cube + int(row['z']) - rad\n",
    "#             ]\n",
    "#             arr = np.where(new_mark == 5200)\n",
    "#             print(arr)\n",
    "#             x = np.unique(arr[0])[2]\n",
    "#             label = np.array([int(row['x']), int(row['y']), int(row['z']), x, x, x, cube])\n",
    "\n",
    "#             np.save(output_path + row['Name'] + '/images/' + \"%d.npy\" % (pat_id), new_shape)\n",
    "#             np.save(output_path + row['Name'] + '/label/' + \"%d.npy\" % (pat_id), label)\n",
    "#             np.save(output_path + row['Name'] + '/label/' + \"%d-2.npy\" % (pat_id), new_mark)\n",
    "#     print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for pat_id in range(15):\n",
    "#     save_into_numpy(pat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func(pat_id, cube = 60):\n",
    "    print(pat_id)\n",
    "\n",
    "    imgs_after_resamp = np.load(output_path + 'images/' + \"%d.npy\" % (pat_id))\n",
    "    data = np.load(output_path + 'label/' + \"%d.npy\" % (pat_id), allow_pickle=True)\n",
    "    cude_size = 2\n",
    "\n",
    "    for row in data:\n",
    "        if row[0] in unknown_landmarks:\n",
    "            mark_img = np.zeros(imgs_after_resamp.shape)\n",
    "            for i in range(-cude_size, cude_size):\n",
    "                for j in range(-cude_size, cude_size):\n",
    "                    for k in range(-cude_size, cude_size):\n",
    "                        mark_img[i+int(row[1]), j+int(row[2]), k+int(row[3])] = 5200\n",
    "            radx = random.randint(0,int((cube*1)/3))\n",
    "            rady = random.randint(0,int((cube*1)/3))\n",
    "            radz = random.randint(0,int((cube*1)/3))\n",
    "            print(row[0])\n",
    "\n",
    "            new_shape = imgs_after_resamp[\n",
    "                int(row[1]) - cube - radx: cube + int(row[1]) - radx,\n",
    "                int(row[2]) - cube - rady: cube + int(row[2]) - rady,\n",
    "                int(row[3]) - cube - radz: cube + int(row[3]) - radz\n",
    "            ]\n",
    "            new_mark = mark_img[\n",
    "                int(row[1]) - cube - radx: cube + int(row[1]) - radx,\n",
    "                int(row[2]) - cube - rady: cube + int(row[2]) - rady,\n",
    "                int(row[3]) - cube - radz: cube + int(row[3]) - radz\n",
    "            ]\n",
    "            label = np.array([int(row[1]), int(row[2]), int(row[3]), cube+radx, cube+rady, cube+radz, cube])\n",
    "\n",
    "            np.save(output_path + row[0] + '/images/' + \"%d.npy\" % (pat_id), new_shape)\n",
    "            np.save(output_path + row[0] + '/label/' + \"%d.npy\" % (pat_id), label)\n",
    "            np.save(output_path + row[0] + '/label/' + \"%d-2.npy\" % (pat_id), new_mark)\n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "1\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "2\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "3\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "4\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "5\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "6\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "7\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "8\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "9\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "10\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "11\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "12\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n",
      "13\n",
      "whitesideReference\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "PCLOrigin\n",
      "medialSulcus\n",
      " \n",
      "14\n",
      "PCLOrigin\n",
      "lateralCondyle\n",
      "medialCondyle\n",
      "medialSulcus\n",
      "whitesideReference\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for pat_id in range(15):\n",
    "    main_func(pat_id, cube = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_func(20-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_func(18-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = np.array(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
