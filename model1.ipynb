{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import os\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "landmarks = [\n",
    "    'PCLOrigin',\n",
    "    'lateralCondyle',\n",
    "    'medialCondyle',\n",
    "    'medialSulcus',\n",
    "    'whitesideReference'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_axis_femur_model(name='PCLOrigin', axis=0, data_size = 15):\n",
    "    output_path = \"/code/\" + name + \"/\"\n",
    "    imgs_to_process = []\n",
    "    lbls_to_process = []\n",
    "    dif_arr = [(0,1,2), (0,2,1), (1,0,2), (1,2,0), (2,0,1), (2,1,0)]\n",
    "    num_classes = 120\n",
    "\n",
    "    for index in range(data_size):\n",
    "        for a, b, c in dif_arr:\n",
    "            imgs_to_process.append(np.load(output_path + 'images/' + '{}-{}-{}-{}.npy'.format(index, a, b, c)))\n",
    "            label = np.load(output_path + 'label/' + '{}-{}-{}-{}.npy'.format(index, a, b, c))\n",
    "            lbls_to_process.append(int(label[3+axis]))\n",
    "            num_classes = int(label[6]) * 2\n",
    "\n",
    "    imgs_to_process = np.array(imgs_to_process)\n",
    "    lbls_to_process = np.array(lbls_to_process)\n",
    "\n",
    "    batch_size = 15\n",
    "    epochs = 200\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(imgs_to_process, lbls_to_process, test_size=0.2)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    img_rows = x_train.shape[1]\n",
    "    img_cols = x_train.shape[2]\n",
    "    colors = x_train.shape[3]\n",
    "\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1,colors, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1,colors, img_rows, img_cols)\n",
    "        input_shape = (1, colors, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, colors, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, colors, 1)\n",
    "        input_shape = (img_rows, img_cols, colors, 1)\n",
    "\n",
    "    print(num_classes)\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(Conv3D(3, kernel_size=(3, 3, 3), activation='relu'))\n",
    "    model.add(Conv3D(3, kernel_size=(1, 1, 1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(3,3,3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer\n",
    "\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes))\n",
    "\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    sgd=SGD(lr=learning_rate)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    model.save('one_axis_femur_model_{}_{}.h5'.format(name, axis))\n",
    "    prediction = model.predict(x_test)\n",
    "    print(prediction)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print(score)\n",
    "    print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (192, 42, 42, 42)\n",
      "192 train samples\n",
      "48 test samples\n",
      "192 train samples\n",
      "48 test samples\n",
      "42\n",
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/200\n",
      "192/192 [==============================] - 16s 83ms/step - loss: 4.3506 - accuracy: 0.0833 - val_loss: 2.7980 - val_accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.8331 - accuracy: 0.2240 - val_loss: 2.6400 - val_accuracy: 0.1250\n",
      "Epoch 3/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.4788 - accuracy: 0.2188 - val_loss: 2.4604 - val_accuracy: 0.0833\n",
      "Epoch 4/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.3343 - accuracy: 0.2396 - val_loss: 2.8587 - val_accuracy: 0.1250\n",
      "Epoch 5/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.3476 - accuracy: 0.2292 - val_loss: 2.2928 - val_accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.1832 - accuracy: 0.2604 - val_loss: 2.3363 - val_accuracy: 0.1042\n",
      "Epoch 7/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.0543 - accuracy: 0.2812 - val_loss: 2.1652 - val_accuracy: 0.1458\n",
      "Epoch 8/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.9219 - accuracy: 0.3177 - val_loss: 2.3127 - val_accuracy: 0.1875\n",
      "Epoch 9/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.9422 - accuracy: 0.3281 - val_loss: 2.1706 - val_accuracy: 0.1875\n",
      "Epoch 10/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.8400 - accuracy: 0.3490 - val_loss: 2.1848 - val_accuracy: 0.1458\n",
      "Epoch 11/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7626 - accuracy: 0.4115 - val_loss: 2.1509 - val_accuracy: 0.1667\n",
      "Epoch 12/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7016 - accuracy: 0.3802 - val_loss: 2.1836 - val_accuracy: 0.2083\n",
      "Epoch 13/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5401 - accuracy: 0.4479 - val_loss: 2.1007 - val_accuracy: 0.1875\n",
      "Epoch 14/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5804 - accuracy: 0.4323 - val_loss: 2.1396 - val_accuracy: 0.1875\n",
      "Epoch 15/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4379 - accuracy: 0.5417 - val_loss: 2.1687 - val_accuracy: 0.2083\n",
      "Epoch 16/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3839 - accuracy: 0.5521 - val_loss: 2.0412 - val_accuracy: 0.2292\n",
      "Epoch 17/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3171 - accuracy: 0.5573 - val_loss: 2.1716 - val_accuracy: 0.2292\n",
      "Epoch 18/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2017 - accuracy: 0.6042 - val_loss: 2.0660 - val_accuracy: 0.2083\n",
      "Epoch 19/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1397 - accuracy: 0.6667 - val_loss: 2.0798 - val_accuracy: 0.2708\n",
      "Epoch 20/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1303 - accuracy: 0.6354 - val_loss: 2.1421 - val_accuracy: 0.2083\n",
      "Epoch 21/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0464 - accuracy: 0.6406 - val_loss: 2.3418 - val_accuracy: 0.1875\n",
      "Epoch 22/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9081 - accuracy: 0.6979 - val_loss: 2.1805 - val_accuracy: 0.2500\n",
      "Epoch 23/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8566 - accuracy: 0.7344 - val_loss: 2.2518 - val_accuracy: 0.2083\n",
      "Epoch 24/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7903 - accuracy: 0.7552 - val_loss: 2.3546 - val_accuracy: 0.2917\n",
      "Epoch 25/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7380 - accuracy: 0.7396 - val_loss: 2.2331 - val_accuracy: 0.2708\n",
      "Epoch 26/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7319 - accuracy: 0.7604 - val_loss: 2.0434 - val_accuracy: 0.2917\n",
      "Epoch 27/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6383 - accuracy: 0.8073 - val_loss: 2.4876 - val_accuracy: 0.2083\n",
      "Epoch 28/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6873 - accuracy: 0.7604 - val_loss: 2.5126 - val_accuracy: 0.2292\n",
      "Epoch 29/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5253 - accuracy: 0.8438 - val_loss: 2.2850 - val_accuracy: 0.3125\n",
      "Epoch 30/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5434 - accuracy: 0.8385 - val_loss: 2.4046 - val_accuracy: 0.3125\n",
      "Epoch 31/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5724 - accuracy: 0.8177 - val_loss: 2.4026 - val_accuracy: 0.2500\n",
      "Epoch 32/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4455 - accuracy: 0.8490 - val_loss: 2.3111 - val_accuracy: 0.2292\n",
      "Epoch 33/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3479 - accuracy: 0.9010 - val_loss: 2.5237 - val_accuracy: 0.2917\n",
      "Epoch 34/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2907 - accuracy: 0.9323 - val_loss: 2.4850 - val_accuracy: 0.2292\n",
      "Epoch 35/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3604 - accuracy: 0.9167 - val_loss: 2.5535 - val_accuracy: 0.2917\n",
      "Epoch 36/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2489 - accuracy: 0.9479 - val_loss: 2.5879 - val_accuracy: 0.2708\n",
      "Epoch 37/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2359 - accuracy: 0.9531 - val_loss: 2.4732 - val_accuracy: 0.2708\n",
      "Epoch 38/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2345 - accuracy: 0.9427 - val_loss: 2.8763 - val_accuracy: 0.2708\n",
      "Epoch 39/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2998 - accuracy: 0.9219 - val_loss: 2.4749 - val_accuracy: 0.2500\n",
      "Epoch 40/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1857 - accuracy: 0.9740 - val_loss: 2.9141 - val_accuracy: 0.2708\n",
      "Epoch 41/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2262 - accuracy: 0.9479 - val_loss: 2.6233 - val_accuracy: 0.3333\n",
      "Epoch 42/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1404 - accuracy: 0.9844 - val_loss: 2.7787 - val_accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1507 - accuracy: 0.9688 - val_loss: 2.6424 - val_accuracy: 0.3333\n",
      "Epoch 44/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1974 - accuracy: 0.9688 - val_loss: 2.7602 - val_accuracy: 0.3958\n",
      "Epoch 45/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1193 - accuracy: 0.9896 - val_loss: 2.8703 - val_accuracy: 0.3125\n",
      "Epoch 46/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1153 - accuracy: 0.9792 - val_loss: 2.7256 - val_accuracy: 0.3542\n",
      "Epoch 47/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1408 - accuracy: 0.9740 - val_loss: 2.7513 - val_accuracy: 0.3125\n",
      "Epoch 48/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0835 - accuracy: 0.9844 - val_loss: 3.0473 - val_accuracy: 0.3542\n",
      "Epoch 49/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 3.1220 - val_accuracy: 0.3542\n",
      "Epoch 50/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0976 - accuracy: 0.9896 - val_loss: 2.8361 - val_accuracy: 0.3958\n",
      "Epoch 51/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1062 - accuracy: 0.9844 - val_loss: 2.9205 - val_accuracy: 0.3542\n",
      "Epoch 52/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0784 - accuracy: 0.9896 - val_loss: 3.0448 - val_accuracy: 0.3750\n",
      "Epoch 53/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0695 - accuracy: 0.9948 - val_loss: 2.8931 - val_accuracy: 0.3750\n",
      "Epoch 54/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0684 - accuracy: 0.9948 - val_loss: 3.0680 - val_accuracy: 0.3542\n",
      "Epoch 55/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0682 - accuracy: 0.9896 - val_loss: 3.0590 - val_accuracy: 0.3333\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0726 - accuracy: 0.9948 - val_loss: 3.0072 - val_accuracy: 0.3542\n",
      "Epoch 57/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0995 - accuracy: 0.9792 - val_loss: 3.0422 - val_accuracy: 0.3542\n",
      "Epoch 58/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0611 - accuracy: 0.9896 - val_loss: 3.0516 - val_accuracy: 0.3750\n",
      "Epoch 59/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 3.1324 - val_accuracy: 0.3750\n",
      "Epoch 60/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0926 - accuracy: 0.9740 - val_loss: 3.2916 - val_accuracy: 0.3542\n",
      "Epoch 61/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 3.2338 - val_accuracy: 0.3542\n",
      "Epoch 62/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0614 - accuracy: 0.9948 - val_loss: 3.3323 - val_accuracy: 0.3333\n",
      "Epoch 63/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0703 - accuracy: 0.9948 - val_loss: 3.4404 - val_accuracy: 0.3125\n",
      "Epoch 64/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0476 - accuracy: 0.9948 - val_loss: 3.9024 - val_accuracy: 0.2708\n",
      "Epoch 65/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1086 - accuracy: 0.9792 - val_loss: 3.3680 - val_accuracy: 0.2708\n",
      "Epoch 66/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0880 - accuracy: 0.9792 - val_loss: 3.4695 - val_accuracy: 0.3125\n",
      "Epoch 67/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 3.4606 - val_accuracy: 0.3333\n",
      "Epoch 68/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1515 - accuracy: 0.9427 - val_loss: 3.2565 - val_accuracy: 0.2083\n",
      "Epoch 69/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2249 - accuracy: 0.9531 - val_loss: 3.3112 - val_accuracy: 0.3333\n",
      "Epoch 70/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0802 - accuracy: 0.9844 - val_loss: 3.0667 - val_accuracy: 0.3333\n",
      "Epoch 71/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0498 - accuracy: 0.9948 - val_loss: 3.0926 - val_accuracy: 0.3750\n",
      "Epoch 72/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0635 - accuracy: 0.9948 - val_loss: 3.3662 - val_accuracy: 0.3333\n",
      "Epoch 73/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0615 - accuracy: 0.9948 - val_loss: 3.3463 - val_accuracy: 0.3333\n",
      "Epoch 74/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0439 - accuracy: 0.9948 - val_loss: 3.0802 - val_accuracy: 0.3750\n",
      "Epoch 75/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0491 - accuracy: 0.9948 - val_loss: 3.3543 - val_accuracy: 0.3333\n",
      "Epoch 76/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 3.6140 - val_accuracy: 0.3958\n",
      "Epoch 77/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0472 - accuracy: 0.9896 - val_loss: 3.5135 - val_accuracy: 0.3958\n",
      "Epoch 78/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0505 - accuracy: 0.9948 - val_loss: 3.1599 - val_accuracy: 0.3542\n",
      "Epoch 79/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0456 - accuracy: 0.9896 - val_loss: 3.6711 - val_accuracy: 0.3542\n",
      "Epoch 80/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.9687 - val_accuracy: 0.3333\n",
      "Epoch 81/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.8385 - val_accuracy: 0.3333\n",
      "Epoch 82/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 3.8160 - val_accuracy: 0.3333\n",
      "Epoch 83/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 4.0227 - val_accuracy: 0.3542\n",
      "Epoch 84/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0754 - accuracy: 0.9740 - val_loss: 4.0832 - val_accuracy: 0.3125\n",
      "Epoch 85/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0395 - accuracy: 0.9948 - val_loss: 3.8848 - val_accuracy: 0.3750\n",
      "Epoch 86/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 3.8721 - val_accuracy: 0.3542\n",
      "Epoch 87/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 3.9517 - val_accuracy: 0.3750\n",
      "Epoch 88/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0317 - accuracy: 0.9948 - val_loss: 4.0034 - val_accuracy: 0.3333\n",
      "Epoch 89/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0984 - accuracy: 0.9688 - val_loss: 3.5254 - val_accuracy: 0.2917\n",
      "Epoch 90/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 3.6707 - val_accuracy: 0.3333\n",
      "Epoch 91/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0293 - accuracy: 0.9948 - val_loss: 3.7011 - val_accuracy: 0.3750\n",
      "Epoch 92/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0302 - accuracy: 0.9948 - val_loss: 3.5228 - val_accuracy: 0.3333\n",
      "Epoch 93/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 3.5636 - val_accuracy: 0.3333\n",
      "Epoch 94/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 3.8951 - val_accuracy: 0.3125\n",
      "Epoch 95/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 3.7622 - val_accuracy: 0.3542\n",
      "Epoch 96/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0276 - accuracy: 0.9948 - val_loss: 3.5460 - val_accuracy: 0.3542\n",
      "Epoch 97/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 3.7930 - val_accuracy: 0.3333\n",
      "Epoch 98/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 4.1271 - val_accuracy: 0.3333\n",
      "Epoch 99/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 4.0344 - val_accuracy: 0.3542\n",
      "Epoch 100/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 4.1200 - val_accuracy: 0.3958\n",
      "Epoch 101/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0222 - accuracy: 0.9948 - val_loss: 4.1119 - val_accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0390 - accuracy: 0.9948 - val_loss: 3.9030 - val_accuracy: 0.3333\n",
      "Epoch 103/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 3.8649 - val_accuracy: 0.3542\n",
      "Epoch 104/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 3.6322 - val_accuracy: 0.3542\n",
      "Epoch 105/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 4.0597 - val_accuracy: 0.3125\n",
      "Epoch 106/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 3.8421 - val_accuracy: 0.3542\n",
      "Epoch 107/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 3.9794 - val_accuracy: 0.3542\n",
      "Epoch 108/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 3.7816 - val_accuracy: 0.3125\n",
      "Epoch 109/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 4.2679 - val_accuracy: 0.2708\n",
      "Epoch 110/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 4.1290 - val_accuracy: 0.3333\n",
      "Epoch 111/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 4.1116 - val_accuracy: 0.2917\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1183 - accuracy: 0.9740 - val_loss: 3.8404 - val_accuracy: 0.3542\n",
      "Epoch 113/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 3.9797 - val_accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.9288 - val_accuracy: 0.3958\n",
      "Epoch 115/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 4.0059 - val_accuracy: 0.3958\n",
      "Epoch 116/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 4.0687 - val_accuracy: 0.3958\n",
      "Epoch 117/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 4.0757 - val_accuracy: 0.3958\n",
      "Epoch 118/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 4.7415 - val_accuracy: 0.3333\n",
      "Epoch 119/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0633 - accuracy: 0.9844 - val_loss: 3.9651 - val_accuracy: 0.3542\n",
      "Epoch 120/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 3.9603 - val_accuracy: 0.3542\n",
      "Epoch 121/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 4.1447 - val_accuracy: 0.3750\n",
      "Epoch 122/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0462 - accuracy: 0.9896 - val_loss: 4.4131 - val_accuracy: 0.2917\n",
      "Epoch 123/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 3.9880 - val_accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 3.9464 - val_accuracy: 0.3958\n",
      "Epoch 125/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0310 - accuracy: 0.9948 - val_loss: 3.5618 - val_accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0247 - accuracy: 0.9948 - val_loss: 3.5089 - val_accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.6059 - val_accuracy: 0.3542\n",
      "Epoch 128/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 3.9134 - val_accuracy: 0.3333\n",
      "Epoch 129/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.9739 - val_accuracy: 0.3542\n",
      "Epoch 130/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 4.1318 - val_accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 4.2115 - val_accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.2038 - val_accuracy: 0.3542\n",
      "Epoch 133/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.2853 - val_accuracy: 0.3542\n",
      "Epoch 134/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 4.2431 - val_accuracy: 0.3750\n",
      "Epoch 135/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 3.9969 - val_accuracy: 0.3958\n",
      "Epoch 136/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0261 - accuracy: 0.9896 - val_loss: 3.9423 - val_accuracy: 0.3958\n",
      "Epoch 137/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.2781 - val_accuracy: 0.3958\n",
      "Epoch 138/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 4.0027 - val_accuracy: 0.3333\n",
      "Epoch 139/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.1761 - val_accuracy: 0.3125\n",
      "Epoch 140/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.0455 - val_accuracy: 0.3542\n",
      "Epoch 141/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.1030 - val_accuracy: 0.2917\n",
      "Epoch 142/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 4.0716 - val_accuracy: 0.2917\n",
      "Epoch 143/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0105 - accuracy: 0.9948 - val_loss: 4.4908 - val_accuracy: 0.2917\n",
      "Epoch 144/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 4.3984 - val_accuracy: 0.2917\n",
      "Epoch 145/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 4.3760 - val_accuracy: 0.2917\n",
      "Epoch 146/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 4.3884 - val_accuracy: 0.2917\n",
      "Epoch 147/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 4.2904 - val_accuracy: 0.3125\n",
      "Epoch 148/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0275 - accuracy: 0.9844 - val_loss: 4.1815 - val_accuracy: 0.2917\n",
      "Epoch 149/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2031 - accuracy: 0.9427 - val_loss: 4.1655 - val_accuracy: 0.3542\n",
      "Epoch 150/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 4.3743 - val_accuracy: 0.3333\n",
      "Epoch 151/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 4.2971 - val_accuracy: 0.3542\n",
      "Epoch 152/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 4.2001 - val_accuracy: 0.3542\n",
      "Epoch 153/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.3202 - val_accuracy: 0.3542\n",
      "Epoch 154/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.2713 - val_accuracy: 0.3333\n",
      "Epoch 155/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.2957 - val_accuracy: 0.3333\n",
      "Epoch 156/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.3378 - val_accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.9986 - val_accuracy: 0.3958\n",
      "Epoch 158/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0108 - accuracy: 0.9948 - val_loss: 4.3695 - val_accuracy: 0.3542\n",
      "Epoch 159/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.4090 - val_accuracy: 0.3542\n",
      "Epoch 160/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.4358 - val_accuracy: 0.3542\n",
      "Epoch 161/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.4742 - val_accuracy: 0.3542\n",
      "Epoch 162/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.4036 - val_accuracy: 0.3542\n",
      "Epoch 163/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.3414 - val_accuracy: 0.3542\n",
      "Epoch 164/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.2650 - val_accuracy: 0.3333\n",
      "Epoch 165/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.2782 - val_accuracy: 0.2917\n",
      "Epoch 166/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.7196 - val_accuracy: 0.2917\n",
      "Epoch 167/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.6774 - val_accuracy: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0105 - accuracy: 0.9948 - val_loss: 4.6296 - val_accuracy: 0.3125\n",
      "Epoch 169/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.5439 - val_accuracy: 0.3125\n",
      "Epoch 170/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 4.5695 - val_accuracy: 0.2917\n",
      "Epoch 171/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.5766 - val_accuracy: 0.2917\n",
      "Epoch 172/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.6395 - val_accuracy: 0.2917\n",
      "Epoch 173/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 4.6426 - val_accuracy: 0.2917\n",
      "Epoch 174/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.3872 - val_accuracy: 0.3333\n",
      "Epoch 175/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.5318 - val_accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.5352 - val_accuracy: 0.3333\n",
      "Epoch 177/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 4.3685 - val_accuracy: 0.3542\n",
      "Epoch 178/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.4740 - val_accuracy: 0.3750\n",
      "Epoch 179/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0084 - accuracy: 0.9948 - val_loss: 4.3412 - val_accuracy: 0.3542\n",
      "Epoch 180/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 4.4697 - val_accuracy: 0.3333\n",
      "Epoch 181/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.4386 - val_accuracy: 0.2917\n",
      "Epoch 182/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.4671 - val_accuracy: 0.3125\n",
      "Epoch 183/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.4556 - val_accuracy: 0.3333\n",
      "Epoch 184/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.4530 - val_accuracy: 0.3333\n",
      "Epoch 185/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.4787 - val_accuracy: 0.3333\n",
      "Epoch 186/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.4273 - val_accuracy: 0.3125\n",
      "Epoch 187/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 4.5942 - val_accuracy: 0.3125\n",
      "Epoch 188/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6039 - val_accuracy: 0.3125\n",
      "Epoch 189/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.6433 - val_accuracy: 0.3125\n",
      "Epoch 190/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.5277 - val_accuracy: 0.3125\n",
      "Epoch 191/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.5794 - val_accuracy: 0.2917\n",
      "Epoch 192/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.6424 - val_accuracy: 0.3125\n",
      "Epoch 193/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.5574 - val_accuracy: 0.3125\n",
      "Epoch 194/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.5712 - val_accuracy: 0.3125\n",
      "Epoch 195/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.6321 - val_accuracy: 0.3125\n",
      "Epoch 196/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.6828 - val_accuracy: 0.3125\n",
      "Epoch 197/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7332 - val_accuracy: 0.3125\n",
      "Epoch 198/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.7530 - val_accuracy: 0.3125\n",
      "Epoch 199/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.7639 - val_accuracy: 0.3125\n",
      "Epoch 200/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.7887 - val_accuracy: 0.3125\n",
      "[[6.83043049e-15 1.03995597e-14 3.24683424e-18 ... 1.81660575e-09\n",
      "  9.40417042e-14 1.44887251e-15]\n",
      " [4.01350342e-11 1.10701188e-11 2.20033323e-12 ... 2.71248714e-12\n",
      "  1.06950025e-10 1.09059442e-06]\n",
      " [2.60282668e-19 1.49873361e-16 1.31074213e-19 ... 2.12359713e-10\n",
      "  5.71667896e-17 1.27495983e-25]\n",
      " ...\n",
      " [3.03774991e-11 7.69303465e-09 2.34464228e-12 ... 7.45480511e-10\n",
      "  9.43017553e-10 5.96637335e-07]\n",
      " [3.79782089e-13 9.52542975e-11 3.91561839e-10 ... 1.18349108e-10\n",
      "  1.28914089e-12 8.62207816e-09]\n",
      " [1.02842011e-28 3.36352251e-32 3.01851756e-32 ... 1.13757106e-29\n",
      "  4.37206404e-22 4.04901989e-24]]\n",
      "Test loss: 4.788664182027181\n",
      "Test accuracy: 0.3125\n",
      "[4.788664182027181, 0.3125]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_axis_femur_model('medialSulcus', 0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (192, 42, 42, 42)\n",
      "192 train samples\n",
      "48 test samples\n",
      "192 train samples\n",
      "48 test samples\n",
      "42\n",
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 4.2359 - accuracy: 0.0833 - val_loss: 3.7920 - val_accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 3.5834 - accuracy: 0.1510 - val_loss: 3.6104 - val_accuracy: 0.1875\n",
      "Epoch 3/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 3.2907 - accuracy: 0.2188 - val_loss: 3.2038 - val_accuracy: 0.1875\n",
      "Epoch 4/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.8698 - accuracy: 0.1823 - val_loss: 2.7165 - val_accuracy: 0.1458\n",
      "Epoch 5/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.3453 - accuracy: 0.2135 - val_loss: 2.4818 - val_accuracy: 0.1875\n",
      "Epoch 6/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.2665 - accuracy: 0.1771 - val_loss: 2.4176 - val_accuracy: 0.1875\n",
      "Epoch 7/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.1256 - accuracy: 0.2656 - val_loss: 2.4499 - val_accuracy: 0.2083\n",
      "Epoch 8/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.1161 - accuracy: 0.2396 - val_loss: 2.3849 - val_accuracy: 0.1458\n",
      "Epoch 9/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.0350 - accuracy: 0.2760 - val_loss: 2.3387 - val_accuracy: 0.1250\n",
      "Epoch 10/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.9070 - accuracy: 0.2760 - val_loss: 2.4512 - val_accuracy: 0.1667\n",
      "Epoch 11/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.9733 - accuracy: 0.2917 - val_loss: 2.2943 - val_accuracy: 0.1458\n",
      "Epoch 12/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.8980 - accuracy: 0.2604 - val_loss: 2.2640 - val_accuracy: 0.1042\n",
      "Epoch 13/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.8877 - accuracy: 0.2917 - val_loss: 2.3862 - val_accuracy: 0.2292\n",
      "Epoch 14/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.8368 - accuracy: 0.3542 - val_loss: 2.3146 - val_accuracy: 0.1458\n",
      "Epoch 15/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.8263 - accuracy: 0.3177 - val_loss: 2.3545 - val_accuracy: 0.0833\n",
      "Epoch 16/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7250 - accuracy: 0.3385 - val_loss: 2.4158 - val_accuracy: 0.2083\n",
      "Epoch 17/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7369 - accuracy: 0.3646 - val_loss: 2.3282 - val_accuracy: 0.1667\n",
      "Epoch 18/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7450 - accuracy: 0.3229 - val_loss: 2.4367 - val_accuracy: 0.1875\n",
      "Epoch 19/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7070 - accuracy: 0.3958 - val_loss: 2.3587 - val_accuracy: 0.1875\n",
      "Epoch 20/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6522 - accuracy: 0.3958 - val_loss: 2.4495 - val_accuracy: 0.2292\n",
      "Epoch 21/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6738 - accuracy: 0.3333 - val_loss: 2.4592 - val_accuracy: 0.1250\n",
      "Epoch 22/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5888 - accuracy: 0.4427 - val_loss: 2.4934 - val_accuracy: 0.1875\n",
      "Epoch 23/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6288 - accuracy: 0.4062 - val_loss: 2.4207 - val_accuracy: 0.2083\n",
      "Epoch 24/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5687 - accuracy: 0.4167 - val_loss: 2.4952 - val_accuracy: 0.2083\n",
      "Epoch 25/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5786 - accuracy: 0.4115 - val_loss: 2.3848 - val_accuracy: 0.1667\n",
      "Epoch 26/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5808 - accuracy: 0.3802 - val_loss: 2.4212 - val_accuracy: 0.2083\n",
      "Epoch 27/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5068 - accuracy: 0.4740 - val_loss: 2.6067 - val_accuracy: 0.1667\n",
      "Epoch 28/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4856 - accuracy: 0.4688 - val_loss: 2.5862 - val_accuracy: 0.1250\n",
      "Epoch 29/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4704 - accuracy: 0.4792 - val_loss: 2.5217 - val_accuracy: 0.2083\n",
      "Epoch 30/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.4183 - accuracy: 0.4740 - val_loss: 2.7150 - val_accuracy: 0.2083\n",
      "Epoch 31/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4413 - accuracy: 0.4844 - val_loss: 2.7952 - val_accuracy: 0.2083\n",
      "Epoch 32/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4033 - accuracy: 0.4844 - val_loss: 2.5931 - val_accuracy: 0.2083\n",
      "Epoch 33/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.3953 - accuracy: 0.4531 - val_loss: 2.6737 - val_accuracy: 0.1667\n",
      "Epoch 34/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3787 - accuracy: 0.5312 - val_loss: 2.6965 - val_accuracy: 0.1667\n",
      "Epoch 35/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3739 - accuracy: 0.4948 - val_loss: 2.6565 - val_accuracy: 0.1458\n",
      "Epoch 36/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3209 - accuracy: 0.5208 - val_loss: 2.6812 - val_accuracy: 0.2083\n",
      "Epoch 37/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3230 - accuracy: 0.5052 - val_loss: 2.6734 - val_accuracy: 0.1875\n",
      "Epoch 38/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2360 - accuracy: 0.5365 - val_loss: 2.9438 - val_accuracy: 0.1250\n",
      "Epoch 39/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2381 - accuracy: 0.5469 - val_loss: 2.9073 - val_accuracy: 0.1667\n",
      "Epoch 40/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2723 - accuracy: 0.5000 - val_loss: 2.8261 - val_accuracy: 0.1667\n",
      "Epoch 41/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1806 - accuracy: 0.5833 - val_loss: 2.9397 - val_accuracy: 0.1458\n",
      "Epoch 42/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2328 - accuracy: 0.5677 - val_loss: 3.0830 - val_accuracy: 0.1667\n",
      "Epoch 43/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1432 - accuracy: 0.5781 - val_loss: 3.2162 - val_accuracy: 0.1250\n",
      "Epoch 44/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1722 - accuracy: 0.5677 - val_loss: 2.9958 - val_accuracy: 0.1667\n",
      "Epoch 45/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1890 - accuracy: 0.5417 - val_loss: 3.0305 - val_accuracy: 0.1667\n",
      "Epoch 46/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2521 - accuracy: 0.5677 - val_loss: 2.7941 - val_accuracy: 0.1875\n",
      "Epoch 47/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1630 - accuracy: 0.5833 - val_loss: 2.9861 - val_accuracy: 0.1458\n",
      "Epoch 48/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1246 - accuracy: 0.5938 - val_loss: 3.0518 - val_accuracy: 0.1458\n",
      "Epoch 49/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1564 - accuracy: 0.5938 - val_loss: 3.1658 - val_accuracy: 0.2083\n",
      "Epoch 50/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1098 - accuracy: 0.5729 - val_loss: 3.2486 - val_accuracy: 0.1875\n",
      "Epoch 51/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0990 - accuracy: 0.6354 - val_loss: 3.0550 - val_accuracy: 0.2083\n",
      "Epoch 52/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1349 - accuracy: 0.5625 - val_loss: 3.1986 - val_accuracy: 0.1875\n",
      "Epoch 53/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1228 - accuracy: 0.5990 - val_loss: 3.0103 - val_accuracy: 0.1667\n",
      "Epoch 54/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0683 - accuracy: 0.6406 - val_loss: 3.2579 - val_accuracy: 0.1667\n",
      "Epoch 55/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0570 - accuracy: 0.6146 - val_loss: 3.3077 - val_accuracy: 0.1667\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0615 - accuracy: 0.5781 - val_loss: 3.5175 - val_accuracy: 0.1667\n",
      "Epoch 57/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0704 - accuracy: 0.5990 - val_loss: 3.5498 - val_accuracy: 0.2083\n",
      "Epoch 58/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0716 - accuracy: 0.6354 - val_loss: 3.4839 - val_accuracy: 0.1875\n",
      "Epoch 59/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1047 - accuracy: 0.5938 - val_loss: 3.3441 - val_accuracy: 0.2292\n",
      "Epoch 60/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9693 - accuracy: 0.6667 - val_loss: 3.7015 - val_accuracy: 0.2083\n",
      "Epoch 61/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1450 - accuracy: 0.6198 - val_loss: 3.4417 - val_accuracy: 0.1875\n",
      "Epoch 62/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9737 - accuracy: 0.6302 - val_loss: 3.7348 - val_accuracy: 0.2292\n",
      "Epoch 63/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0756 - accuracy: 0.5833 - val_loss: 3.7739 - val_accuracy: 0.1250\n",
      "Epoch 64/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0260 - accuracy: 0.6302 - val_loss: 3.8244 - val_accuracy: 0.1250\n",
      "Epoch 65/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9492 - accuracy: 0.6094 - val_loss: 3.7019 - val_accuracy: 0.1458\n",
      "Epoch 66/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9849 - accuracy: 0.6406 - val_loss: 3.8997 - val_accuracy: 0.1458\n",
      "Epoch 67/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9307 - accuracy: 0.6667 - val_loss: 4.1215 - val_accuracy: 0.1875\n",
      "Epoch 68/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9674 - accuracy: 0.6562 - val_loss: 4.0380 - val_accuracy: 0.1667\n",
      "Epoch 69/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8954 - accuracy: 0.6667 - val_loss: 4.4318 - val_accuracy: 0.1458\n",
      "Epoch 70/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9268 - accuracy: 0.6354 - val_loss: 4.1321 - val_accuracy: 0.1667\n",
      "Epoch 71/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8397 - accuracy: 0.7031 - val_loss: 4.0745 - val_accuracy: 0.1667\n",
      "Epoch 72/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9713 - accuracy: 0.6354 - val_loss: 2.9934 - val_accuracy: 0.2292\n",
      "Epoch 73/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8914 - accuracy: 0.6823 - val_loss: 3.4331 - val_accuracy: 0.2083\n",
      "Epoch 74/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9527 - accuracy: 0.6406 - val_loss: 3.5430 - val_accuracy: 0.2292\n",
      "Epoch 75/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8547 - accuracy: 0.6875 - val_loss: 3.8028 - val_accuracy: 0.1875\n",
      "Epoch 76/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8522 - accuracy: 0.6979 - val_loss: 4.0866 - val_accuracy: 0.2708\n",
      "Epoch 77/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8807 - accuracy: 0.6510 - val_loss: 3.6258 - val_accuracy: 0.1875\n",
      "Epoch 78/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8168 - accuracy: 0.7031 - val_loss: 4.5367 - val_accuracy: 0.1875\n",
      "Epoch 79/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8389 - accuracy: 0.7135 - val_loss: 4.0546 - val_accuracy: 0.2083\n",
      "Epoch 80/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8263 - accuracy: 0.6875 - val_loss: 3.8664 - val_accuracy: 0.1667\n",
      "Epoch 81/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8266 - accuracy: 0.6823 - val_loss: 4.0516 - val_accuracy: 0.2292\n",
      "Epoch 82/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7922 - accuracy: 0.7031 - val_loss: 4.2381 - val_accuracy: 0.2083\n",
      "Epoch 83/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7902 - accuracy: 0.7135 - val_loss: 4.1870 - val_accuracy: 0.1875\n",
      "Epoch 84/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8113 - accuracy: 0.6823 - val_loss: 4.4302 - val_accuracy: 0.2083\n",
      "Epoch 85/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9226 - accuracy: 0.6406 - val_loss: 3.8180 - val_accuracy: 0.2292\n",
      "Epoch 86/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7861 - accuracy: 0.7083 - val_loss: 4.3969 - val_accuracy: 0.1875\n",
      "Epoch 87/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8882 - accuracy: 0.6823 - val_loss: 4.2703 - val_accuracy: 0.2292\n",
      "Epoch 88/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8089 - accuracy: 0.7135 - val_loss: 4.4925 - val_accuracy: 0.2292\n",
      "Epoch 89/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7372 - accuracy: 0.6927 - val_loss: 4.4348 - val_accuracy: 0.1667\n",
      "Epoch 90/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8195 - accuracy: 0.7083 - val_loss: 3.8382 - val_accuracy: 0.2083\n",
      "Epoch 91/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7362 - accuracy: 0.7292 - val_loss: 4.3424 - val_accuracy: 0.1875\n",
      "Epoch 92/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7186 - accuracy: 0.7396 - val_loss: 4.6958 - val_accuracy: 0.2083\n",
      "Epoch 93/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6926 - accuracy: 0.7604 - val_loss: 4.6123 - val_accuracy: 0.1458\n",
      "Epoch 94/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7638 - accuracy: 0.7500 - val_loss: 4.5492 - val_accuracy: 0.2083\n",
      "Epoch 95/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6788 - accuracy: 0.7552 - val_loss: 4.8579 - val_accuracy: 0.2500\n",
      "Epoch 96/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6905 - accuracy: 0.7396 - val_loss: 4.9954 - val_accuracy: 0.1875\n",
      "Epoch 97/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7205 - accuracy: 0.7083 - val_loss: 5.3625 - val_accuracy: 0.2292\n",
      "Epoch 98/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6939 - accuracy: 0.7188 - val_loss: 5.2369 - val_accuracy: 0.1875\n",
      "Epoch 99/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6662 - accuracy: 0.7292 - val_loss: 5.7304 - val_accuracy: 0.2083\n",
      "Epoch 100/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8931 - accuracy: 0.7292 - val_loss: 3.9338 - val_accuracy: 0.2083\n",
      "Epoch 101/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7419 - accuracy: 0.7500 - val_loss: 4.4111 - val_accuracy: 0.2083\n",
      "Epoch 102/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7154 - accuracy: 0.7448 - val_loss: 4.6839 - val_accuracy: 0.1458\n",
      "Epoch 103/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6422 - accuracy: 0.7708 - val_loss: 4.8801 - val_accuracy: 0.1875\n",
      "Epoch 104/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6173 - accuracy: 0.7760 - val_loss: 5.2195 - val_accuracy: 0.1875\n",
      "Epoch 105/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6006 - accuracy: 0.7865 - val_loss: 5.3682 - val_accuracy: 0.1667\n",
      "Epoch 106/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8545 - accuracy: 0.6979 - val_loss: 5.8365 - val_accuracy: 0.1667\n",
      "Epoch 107/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5758 - accuracy: 0.7812 - val_loss: 5.7546 - val_accuracy: 0.2083\n",
      "Epoch 108/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6370 - accuracy: 0.7917 - val_loss: 4.6180 - val_accuracy: 0.2500\n",
      "Epoch 109/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6193 - accuracy: 0.7552 - val_loss: 6.1894 - val_accuracy: 0.1458\n",
      "Epoch 110/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5594 - accuracy: 0.8177 - val_loss: 6.4630 - val_accuracy: 0.1667\n",
      "Epoch 111/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5213 - accuracy: 0.8073 - val_loss: 7.1393 - val_accuracy: 0.2083\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5150 - accuracy: 0.8073 - val_loss: 7.7489 - val_accuracy: 0.2083\n",
      "Epoch 113/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6364 - accuracy: 0.8021 - val_loss: 5.8232 - val_accuracy: 0.2292\n",
      "Epoch 114/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6808 - accuracy: 0.7448 - val_loss: 4.4340 - val_accuracy: 0.1875\n",
      "Epoch 115/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6605 - accuracy: 0.7552 - val_loss: 5.8354 - val_accuracy: 0.1875\n",
      "Epoch 116/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4839 - accuracy: 0.8438 - val_loss: 6.5730 - val_accuracy: 0.1875\n",
      "Epoch 117/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5602 - accuracy: 0.8021 - val_loss: 6.3944 - val_accuracy: 0.1667\n",
      "Epoch 118/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5373 - accuracy: 0.8073 - val_loss: 6.5188 - val_accuracy: 0.2292\n",
      "Epoch 119/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5385 - accuracy: 0.8125 - val_loss: 7.2178 - val_accuracy: 0.1875\n",
      "Epoch 120/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4868 - accuracy: 0.8385 - val_loss: 7.2878 - val_accuracy: 0.1875\n",
      "Epoch 121/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5042 - accuracy: 0.8177 - val_loss: 7.5103 - val_accuracy: 0.1875\n",
      "Epoch 122/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5463 - accuracy: 0.7969 - val_loss: 5.2550 - val_accuracy: 0.1667\n",
      "Epoch 123/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5846 - accuracy: 0.7969 - val_loss: 6.1062 - val_accuracy: 0.1458\n",
      "Epoch 124/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6414 - accuracy: 0.7917 - val_loss: 6.8370 - val_accuracy: 0.1458\n",
      "Epoch 125/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4586 - accuracy: 0.8281 - val_loss: 6.9112 - val_accuracy: 0.2083\n",
      "Epoch 126/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5344 - accuracy: 0.8073 - val_loss: 7.0514 - val_accuracy: 0.1667\n",
      "Epoch 127/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4668 - accuracy: 0.8385 - val_loss: 7.4953 - val_accuracy: 0.2083\n",
      "Epoch 128/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4123 - accuracy: 0.8698 - val_loss: 8.0330 - val_accuracy: 0.1875\n",
      "Epoch 129/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4177 - accuracy: 0.8594 - val_loss: 8.0358 - val_accuracy: 0.1667\n",
      "Epoch 130/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5713 - accuracy: 0.8125 - val_loss: 6.5821 - val_accuracy: 0.1875\n",
      "Epoch 131/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4970 - accuracy: 0.8281 - val_loss: 6.0991 - val_accuracy: 0.2708\n",
      "Epoch 132/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4637 - accuracy: 0.8698 - val_loss: 7.3697 - val_accuracy: 0.2083\n",
      "Epoch 133/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4742 - accuracy: 0.8333 - val_loss: 8.4537 - val_accuracy: 0.2083\n",
      "Epoch 134/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4971 - accuracy: 0.8125 - val_loss: 7.3677 - val_accuracy: 0.1875\n",
      "Epoch 135/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5075 - accuracy: 0.8177 - val_loss: 6.9772 - val_accuracy: 0.1875\n",
      "Epoch 136/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4032 - accuracy: 0.8438 - val_loss: 6.6694 - val_accuracy: 0.2708\n",
      "Epoch 137/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3688 - accuracy: 0.8698 - val_loss: 7.7529 - val_accuracy: 0.2500\n",
      "Epoch 138/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3629 - accuracy: 0.8646 - val_loss: 8.8604 - val_accuracy: 0.2083\n",
      "Epoch 139/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3647 - accuracy: 0.8750 - val_loss: 8.7687 - val_accuracy: 0.1875\n",
      "Epoch 140/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3467 - accuracy: 0.8490 - val_loss: 8.4795 - val_accuracy: 0.2500\n",
      "Epoch 141/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2892 - accuracy: 0.8958 - val_loss: 8.8007 - val_accuracy: 0.2083\n",
      "Epoch 142/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3986 - accuracy: 0.8646 - val_loss: 9.6850 - val_accuracy: 0.1667\n",
      "Epoch 143/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.4795 - accuracy: 0.8229 - val_loss: 6.5833 - val_accuracy: 0.2292\n",
      "Epoch 144/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3965 - accuracy: 0.8542 - val_loss: 8.4051 - val_accuracy: 0.2500\n",
      "Epoch 145/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3741 - accuracy: 0.8750 - val_loss: 8.7572 - val_accuracy: 0.2500\n",
      "Epoch 146/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3307 - accuracy: 0.8750 - val_loss: 10.6338 - val_accuracy: 0.2292\n",
      "Epoch 147/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2734 - accuracy: 0.9010 - val_loss: 9.4546 - val_accuracy: 0.2292\n",
      "Epoch 154/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3377 - accuracy: 0.9062 - val_loss: 9.6284 - val_accuracy: 0.1667\n",
      "Epoch 155/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2562 - accuracy: 0.9271 - val_loss: 11.2559 - val_accuracy: 0.1667\n",
      "Epoch 156/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2827 - accuracy: 0.8906 - val_loss: 8.5671 - val_accuracy: 0.2083\n",
      "Epoch 157/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2471 - accuracy: 0.9115 - val_loss: 8.8855 - val_accuracy: 0.2292\n",
      "Epoch 158/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2514 - accuracy: 0.9219 - val_loss: 9.3223 - val_accuracy: 0.1875\n",
      "Epoch 159/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3026 - accuracy: 0.8958 - val_loss: 9.5737 - val_accuracy: 0.2083\n",
      "Epoch 160/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3043 - accuracy: 0.9010 - val_loss: 10.6965 - val_accuracy: 0.1875\n",
      "Epoch 161/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2488 - accuracy: 0.9167 - val_loss: 10.2300 - val_accuracy: 0.2292\n",
      "Epoch 162/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4284 - accuracy: 0.8906 - val_loss: 7.5502 - val_accuracy: 0.1667\n",
      "Epoch 163/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.3487 - accuracy: 0.9062 - val_loss: 11.0337 - val_accuracy: 0.1667\n",
      "Epoch 164/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5513 - accuracy: 0.8333 - val_loss: 7.8872 - val_accuracy: 0.2292\n",
      "Epoch 165/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3081 - accuracy: 0.8906 - val_loss: 12.2723 - val_accuracy: 0.1875\n",
      "Epoch 166/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2457 - accuracy: 0.9010 - val_loss: 9.5433 - val_accuracy: 0.2083\n",
      "Epoch 167/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2158 - accuracy: 0.9167 - val_loss: 12.0680 - val_accuracy: 0.2083\n",
      "Epoch 168/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2588 - accuracy: 0.9271 - val_loss: 10.6082 - val_accuracy: 0.2500\n",
      "Epoch 169/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2245 - accuracy: 0.9323 - val_loss: 12.9155 - val_accuracy: 0.1875\n",
      "Epoch 170/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1695 - accuracy: 0.9427 - val_loss: 13.1457 - val_accuracy: 0.2292\n",
      "Epoch 171/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2505 - accuracy: 0.9167 - val_loss: 10.1422 - val_accuracy: 0.2500\n",
      "Epoch 172/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1850 - accuracy: 0.9219 - val_loss: 11.1656 - val_accuracy: 0.2500\n",
      "Epoch 173/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2382 - accuracy: 0.9167 - val_loss: 11.1750 - val_accuracy: 0.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.4828 - accuracy: 0.8854 - val_loss: 11.0499 - val_accuracy: 0.2083\n",
      "Epoch 175/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2844 - accuracy: 0.8958 - val_loss: 12.0770 - val_accuracy: 0.1875\n",
      "Epoch 176/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2841 - accuracy: 0.8958 - val_loss: 10.9598 - val_accuracy: 0.2083\n",
      "Epoch 177/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2340 - accuracy: 0.9062 - val_loss: 14.2021 - val_accuracy: 0.2083\n",
      "Epoch 178/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1922 - accuracy: 0.9323 - val_loss: 15.0336 - val_accuracy: 0.1667\n",
      "Epoch 179/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1882 - accuracy: 0.9427 - val_loss: 15.1001 - val_accuracy: 0.1458\n",
      "Epoch 180/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1982 - accuracy: 0.9219 - val_loss: 10.5034 - val_accuracy: 0.2083\n",
      "Epoch 181/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7320 - accuracy: 0.8073 - val_loss: 10.3482 - val_accuracy: 0.1667\n",
      "Epoch 182/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.3237 - accuracy: 0.9219 - val_loss: 10.4836 - val_accuracy: 0.1667\n",
      "Epoch 183/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1871 - accuracy: 0.9323 - val_loss: 11.3667 - val_accuracy: 0.1458\n",
      "Epoch 184/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1570 - accuracy: 0.9531 - val_loss: 13.0585 - val_accuracy: 0.1458\n",
      "Epoch 185/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1347 - accuracy: 0.9688 - val_loss: 14.0322 - val_accuracy: 0.1875\n",
      "Epoch 186/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1296 - accuracy: 0.9531 - val_loss: 14.8881 - val_accuracy: 0.1875\n",
      "Epoch 187/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1611 - accuracy: 0.9427 - val_loss: 13.0363 - val_accuracy: 0.1875\n",
      "Epoch 188/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1438 - accuracy: 0.9531 - val_loss: 14.4655 - val_accuracy: 0.1875\n",
      "Epoch 189/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1359 - accuracy: 0.9479 - val_loss: 17.2362 - val_accuracy: 0.1667\n",
      "Epoch 190/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1110 - accuracy: 0.9583 - val_loss: 17.9481 - val_accuracy: 0.1875\n",
      "Epoch 191/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1993 - accuracy: 0.9219 - val_loss: 15.7142 - val_accuracy: 0.1667\n",
      "Epoch 192/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1530 - accuracy: 0.9323 - val_loss: 14.9870 - val_accuracy: 0.2083\n",
      "Epoch 193/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1203 - accuracy: 0.9583 - val_loss: 16.0637 - val_accuracy: 0.2292\n",
      "Epoch 194/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2037 - accuracy: 0.9271 - val_loss: 10.9653 - val_accuracy: 0.2292\n",
      "Epoch 195/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.1988 - accuracy: 0.9271 - val_loss: 15.3230 - val_accuracy: 0.1875\n",
      "Epoch 196/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.2706 - accuracy: 0.9115 - val_loss: 12.5741 - val_accuracy: 0.2083\n",
      "Epoch 197/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.2323 - accuracy: 0.9427 - val_loss: 12.5888 - val_accuracy: 0.1875\n",
      "Epoch 198/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1842 - accuracy: 0.9323 - val_loss: 14.2613 - val_accuracy: 0.1667\n",
      "Epoch 199/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1379 - accuracy: 0.9583 - val_loss: 13.8961 - val_accuracy: 0.1875\n",
      "Epoch 200/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.1607 - accuracy: 0.9375 - val_loss: 14.2248 - val_accuracy: 0.2083\n",
      "[[1.92657717e-12 5.67541498e-08 1.09154588e-13 ... 7.68909957e-18\n",
      "  6.93682199e-13 9.74599956e-10]\n",
      " [1.09828473e-10 6.10961143e-11 6.94785679e-12 ... 1.90777732e-13\n",
      "  1.62867712e-13 2.29070669e-11]\n",
      " [2.39094559e-33 2.61879086e-23 0.00000000e+00 ... 2.51291014e-38\n",
      "  9.47158654e-30 8.64010447e-32]\n",
      " ...\n",
      " [8.52999745e-13 2.97026986e-07 3.39995805e-12 ... 1.05048702e-16\n",
      "  6.90957187e-12 2.60232003e-10]\n",
      " [7.25184288e-11 4.43816397e-08 5.05185005e-10 ... 2.00133557e-14\n",
      "  4.79503590e-13 8.21568804e-08]\n",
      " [1.08543707e-09 8.62033539e-06 2.62271925e-07 ... 1.06917517e-10\n",
      "  4.06574913e-10 3.32136429e-09]]\n",
      "Test loss: 14.224836349487305\n",
      "Test accuracy: 0.2083333283662796\n",
      "[14.224836349487305, 0.2083333283662796]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_axis_femur_model('medialSulcus', 1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (192, 42, 42, 42)\n",
      "192 train samples\n",
      "48 test samples\n",
      "192 train samples\n",
      "48 test samples\n",
      "42\n",
      "Train on 192 samples, validate on 48 samples\n",
      "Epoch 1/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 4.4244 - accuracy: 0.0417 - val_loss: 3.7438 - val_accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 3.6604 - accuracy: 0.0365 - val_loss: 3.6601 - val_accuracy: 0.1250\n",
      "Epoch 3/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 3.4750 - accuracy: 0.1667 - val_loss: 3.3392 - val_accuracy: 0.2083\n",
      "Epoch 4/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.9991 - accuracy: 0.2135 - val_loss: 2.7164 - val_accuracy: 0.2292\n",
      "Epoch 5/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.4618 - accuracy: 0.2500 - val_loss: 2.3825 - val_accuracy: 0.2500\n",
      "Epoch 6/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.2093 - accuracy: 0.2448 - val_loss: 2.3503 - val_accuracy: 0.2083\n",
      "Epoch 7/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.1146 - accuracy: 0.2812 - val_loss: 2.1577 - val_accuracy: 0.2292\n",
      "Epoch 8/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 2.0378 - accuracy: 0.2865 - val_loss: 2.1555 - val_accuracy: 0.1458\n",
      "Epoch 9/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 2.0114 - accuracy: 0.2344 - val_loss: 2.2027 - val_accuracy: 0.2292\n",
      "Epoch 10/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.9616 - accuracy: 0.3021 - val_loss: 2.1713 - val_accuracy: 0.2292\n",
      "Epoch 11/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.9850 - accuracy: 0.2292 - val_loss: 2.1857 - val_accuracy: 0.2083\n",
      "Epoch 12/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.8625 - accuracy: 0.3177 - val_loss: 2.1450 - val_accuracy: 0.2083\n",
      "Epoch 13/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.9163 - accuracy: 0.2969 - val_loss: 2.1271 - val_accuracy: 0.2500\n",
      "Epoch 14/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7468 - accuracy: 0.3594 - val_loss: 2.2223 - val_accuracy: 0.2083\n",
      "Epoch 15/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7580 - accuracy: 0.3490 - val_loss: 2.2405 - val_accuracy: 0.1667\n",
      "Epoch 16/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.7154 - accuracy: 0.3385 - val_loss: 2.1884 - val_accuracy: 0.2083\n",
      "Epoch 17/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7050 - accuracy: 0.3281 - val_loss: 2.1904 - val_accuracy: 0.1667\n",
      "Epoch 18/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7135 - accuracy: 0.3594 - val_loss: 2.1749 - val_accuracy: 0.1875\n",
      "Epoch 19/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6441 - accuracy: 0.3802 - val_loss: 2.2101 - val_accuracy: 0.2292\n",
      "Epoch 20/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.7118 - accuracy: 0.3646 - val_loss: 2.1851 - val_accuracy: 0.1875\n",
      "Epoch 21/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.6833 - accuracy: 0.3750 - val_loss: 2.2289 - val_accuracy: 0.1875\n",
      "Epoch 22/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6283 - accuracy: 0.3802 - val_loss: 2.2770 - val_accuracy: 0.2083\n",
      "Epoch 23/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6543 - accuracy: 0.4010 - val_loss: 2.1632 - val_accuracy: 0.1875\n",
      "Epoch 24/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5729 - accuracy: 0.4115 - val_loss: 2.2177 - val_accuracy: 0.1667\n",
      "Epoch 25/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6237 - accuracy: 0.4479 - val_loss: 2.1799 - val_accuracy: 0.2708\n",
      "Epoch 26/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5851 - accuracy: 0.4115 - val_loss: 2.2947 - val_accuracy: 0.2292\n",
      "Epoch 27/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4841 - accuracy: 0.4427 - val_loss: 2.2980 - val_accuracy: 0.2292\n",
      "Epoch 28/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6049 - accuracy: 0.3958 - val_loss: 2.3631 - val_accuracy: 0.2083\n",
      "Epoch 29/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5099 - accuracy: 0.4896 - val_loss: 2.2431 - val_accuracy: 0.1667\n",
      "Epoch 30/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5161 - accuracy: 0.4323 - val_loss: 2.3170 - val_accuracy: 0.1875\n",
      "Epoch 31/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5334 - accuracy: 0.4167 - val_loss: 2.2054 - val_accuracy: 0.2292\n",
      "Epoch 32/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5535 - accuracy: 0.3854 - val_loss: 2.2673 - val_accuracy: 0.1250\n",
      "Epoch 33/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4050 - accuracy: 0.4688 - val_loss: 2.2272 - val_accuracy: 0.2292\n",
      "Epoch 34/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.5077 - accuracy: 0.4375 - val_loss: 2.3236 - val_accuracy: 0.2500\n",
      "Epoch 35/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4526 - accuracy: 0.4635 - val_loss: 2.2766 - val_accuracy: 0.2500\n",
      "Epoch 36/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4454 - accuracy: 0.4375 - val_loss: 2.2642 - val_accuracy: 0.2292\n",
      "Epoch 37/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4534 - accuracy: 0.4167 - val_loss: 2.3343 - val_accuracy: 0.1875\n",
      "Epoch 38/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.4483 - accuracy: 0.4531 - val_loss: 2.3454 - val_accuracy: 0.1458\n",
      "Epoch 39/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3954 - accuracy: 0.4948 - val_loss: 2.3986 - val_accuracy: 0.2500\n",
      "Epoch 40/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.4013 - accuracy: 0.4635 - val_loss: 2.2879 - val_accuracy: 0.1875\n",
      "Epoch 41/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3856 - accuracy: 0.4740 - val_loss: 2.3408 - val_accuracy: 0.1458\n",
      "Epoch 42/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3913 - accuracy: 0.4740 - val_loss: 2.3963 - val_accuracy: 0.1667\n",
      "Epoch 43/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3538 - accuracy: 0.5052 - val_loss: 2.4634 - val_accuracy: 0.2500\n",
      "Epoch 44/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3991 - accuracy: 0.4740 - val_loss: 2.4600 - val_accuracy: 0.2708\n",
      "Epoch 45/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3264 - accuracy: 0.5104 - val_loss: 2.4645 - val_accuracy: 0.2292\n",
      "Epoch 46/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.3907 - accuracy: 0.4844 - val_loss: 2.5420 - val_accuracy: 0.2083\n",
      "Epoch 47/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2949 - accuracy: 0.5156 - val_loss: 2.5403 - val_accuracy: 0.2500\n",
      "Epoch 48/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3160 - accuracy: 0.5156 - val_loss: 2.5392 - val_accuracy: 0.2083\n",
      "Epoch 49/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2306 - accuracy: 0.5365 - val_loss: 2.6285 - val_accuracy: 0.2292\n",
      "Epoch 50/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2909 - accuracy: 0.5469 - val_loss: 2.5865 - val_accuracy: 0.1875\n",
      "Epoch 51/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3050 - accuracy: 0.5260 - val_loss: 2.5155 - val_accuracy: 0.2708\n",
      "Epoch 52/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2512 - accuracy: 0.5208 - val_loss: 2.5692 - val_accuracy: 0.2292\n",
      "Epoch 53/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2714 - accuracy: 0.5000 - val_loss: 2.5402 - val_accuracy: 0.2292\n",
      "Epoch 54/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2786 - accuracy: 0.5156 - val_loss: 2.6095 - val_accuracy: 0.2500\n",
      "Epoch 55/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2573 - accuracy: 0.5052 - val_loss: 2.7970 - val_accuracy: 0.2292\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2920 - accuracy: 0.5104 - val_loss: 2.7876 - val_accuracy: 0.2083\n",
      "Epoch 57/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2696 - accuracy: 0.5156 - val_loss: 2.9688 - val_accuracy: 0.2083\n",
      "Epoch 58/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.3830 - accuracy: 0.4844 - val_loss: 2.5894 - val_accuracy: 0.2500\n",
      "Epoch 59/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2659 - accuracy: 0.5260 - val_loss: 2.7118 - val_accuracy: 0.2500\n",
      "Epoch 60/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1791 - accuracy: 0.5729 - val_loss: 2.7583 - val_accuracy: 0.2500\n",
      "Epoch 61/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1898 - accuracy: 0.5365 - val_loss: 2.8357 - val_accuracy: 0.1667\n",
      "Epoch 62/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2447 - accuracy: 0.5729 - val_loss: 2.7707 - val_accuracy: 0.1875\n",
      "Epoch 63/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2497 - accuracy: 0.5260 - val_loss: 2.6955 - val_accuracy: 0.2292\n",
      "Epoch 64/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2912 - accuracy: 0.5156 - val_loss: 2.6994 - val_accuracy: 0.2292\n",
      "Epoch 65/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2445 - accuracy: 0.5260 - val_loss: 2.8932 - val_accuracy: 0.2083\n",
      "Epoch 66/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2110 - accuracy: 0.5312 - val_loss: 2.9139 - val_accuracy: 0.2083\n",
      "Epoch 67/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2686 - accuracy: 0.5104 - val_loss: 2.9653 - val_accuracy: 0.2083\n",
      "Epoch 68/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2585 - accuracy: 0.5104 - val_loss: 2.9591 - val_accuracy: 0.2500\n",
      "Epoch 69/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3481 - accuracy: 0.5260 - val_loss: 2.9323 - val_accuracy: 0.2083\n",
      "Epoch 70/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.3221 - accuracy: 0.4844 - val_loss: 2.7561 - val_accuracy: 0.2292\n",
      "Epoch 71/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2703 - accuracy: 0.5000 - val_loss: 3.0994 - val_accuracy: 0.1667\n",
      "Epoch 72/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.3767 - accuracy: 0.5000 - val_loss: 2.8725 - val_accuracy: 0.2500\n",
      "Epoch 73/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1664 - accuracy: 0.5729 - val_loss: 3.0130 - val_accuracy: 0.2083\n",
      "Epoch 74/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2229 - accuracy: 0.5156 - val_loss: 2.9296 - val_accuracy: 0.2083\n",
      "Epoch 75/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2158 - accuracy: 0.5156 - val_loss: 3.2870 - val_accuracy: 0.1667\n",
      "Epoch 76/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2758 - accuracy: 0.4948 - val_loss: 2.9684 - val_accuracy: 0.2500\n",
      "Epoch 77/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1880 - accuracy: 0.5312 - val_loss: 2.9805 - val_accuracy: 0.2083\n",
      "Epoch 78/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1446 - accuracy: 0.5521 - val_loss: 3.1357 - val_accuracy: 0.1875\n",
      "Epoch 79/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1593 - accuracy: 0.5625 - val_loss: 3.1997 - val_accuracy: 0.2083\n",
      "Epoch 80/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2392 - accuracy: 0.5208 - val_loss: 3.0641 - val_accuracy: 0.1875\n",
      "Epoch 81/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1590 - accuracy: 0.5521 - val_loss: 3.1250 - val_accuracy: 0.2500\n",
      "Epoch 82/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1490 - accuracy: 0.5260 - val_loss: 2.9596 - val_accuracy: 0.2500\n",
      "Epoch 83/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1974 - accuracy: 0.5677 - val_loss: 2.9982 - val_accuracy: 0.2083\n",
      "Epoch 84/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1604 - accuracy: 0.5625 - val_loss: 3.1523 - val_accuracy: 0.2292\n",
      "Epoch 85/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1129 - accuracy: 0.5781 - val_loss: 3.0755 - val_accuracy: 0.2500\n",
      "Epoch 86/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1196 - accuracy: 0.5677 - val_loss: 3.2543 - val_accuracy: 0.2083\n",
      "Epoch 87/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0797 - accuracy: 0.6042 - val_loss: 3.2043 - val_accuracy: 0.2708\n",
      "Epoch 88/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0845 - accuracy: 0.5938 - val_loss: 3.2261 - val_accuracy: 0.2917\n",
      "Epoch 89/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.1301 - accuracy: 0.5833 - val_loss: 3.7099 - val_accuracy: 0.1875\n",
      "Epoch 90/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2368 - accuracy: 0.5260 - val_loss: 3.3300 - val_accuracy: 0.2500\n",
      "Epoch 91/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0772 - accuracy: 0.5833 - val_loss: 3.3788 - val_accuracy: 0.2708\n",
      "Epoch 92/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0850 - accuracy: 0.5781 - val_loss: 3.4437 - val_accuracy: 0.2708\n",
      "Epoch 93/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0711 - accuracy: 0.6094 - val_loss: 3.5660 - val_accuracy: 0.1875\n",
      "Epoch 94/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2309 - accuracy: 0.5260 - val_loss: 3.7362 - val_accuracy: 0.2500\n",
      "Epoch 95/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0651 - accuracy: 0.5833 - val_loss: 3.4151 - val_accuracy: 0.2708\n",
      "Epoch 96/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0383 - accuracy: 0.5990 - val_loss: 3.6238 - val_accuracy: 0.2500\n",
      "Epoch 97/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0350 - accuracy: 0.5625 - val_loss: 3.5789 - val_accuracy: 0.2708\n",
      "Epoch 98/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1222 - accuracy: 0.5990 - val_loss: 3.6510 - val_accuracy: 0.3125\n",
      "Epoch 99/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0419 - accuracy: 0.6146 - val_loss: 4.0115 - val_accuracy: 0.2292\n",
      "Epoch 100/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1125 - accuracy: 0.5938 - val_loss: 4.9915 - val_accuracy: 0.2083\n",
      "Epoch 101/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1458 - accuracy: 0.5729 - val_loss: 3.5287 - val_accuracy: 0.2708\n",
      "Epoch 102/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0583 - accuracy: 0.5781 - val_loss: 3.7120 - val_accuracy: 0.2500\n",
      "Epoch 103/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0221 - accuracy: 0.6198 - val_loss: 3.6518 - val_accuracy: 0.2708\n",
      "Epoch 104/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9776 - accuracy: 0.6250 - val_loss: 3.7046 - val_accuracy: 0.2292\n",
      "Epoch 105/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0427 - accuracy: 0.6042 - val_loss: 3.9689 - val_accuracy: 0.1875\n",
      "Epoch 106/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0523 - accuracy: 0.5990 - val_loss: 4.0409 - val_accuracy: 0.1875\n",
      "Epoch 107/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9946 - accuracy: 0.6406 - val_loss: 4.1031 - val_accuracy: 0.2708\n",
      "Epoch 108/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9948 - accuracy: 0.6198 - val_loss: 4.0533 - val_accuracy: 0.2917\n",
      "Epoch 109/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0034 - accuracy: 0.6302 - val_loss: 3.9985 - val_accuracy: 0.2083\n",
      "Epoch 110/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9477 - accuracy: 0.6406 - val_loss: 3.8999 - val_accuracy: 0.2083\n",
      "Epoch 111/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0130 - accuracy: 0.6250 - val_loss: 4.1454 - val_accuracy: 0.2917\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9847 - accuracy: 0.6094 - val_loss: 4.1812 - val_accuracy: 0.2292\n",
      "Epoch 113/200\n",
      "192/192 [==============================] - 17s 89ms/step - loss: 0.9549 - accuracy: 0.6302 - val_loss: 4.2061 - val_accuracy: 0.2917\n",
      "Epoch 114/200\n",
      "192/192 [==============================] - 18s 94ms/step - loss: 0.9285 - accuracy: 0.6562 - val_loss: 4.2579 - val_accuracy: 0.2500\n",
      "Epoch 115/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.1752 - accuracy: 0.5938 - val_loss: 4.2016 - val_accuracy: 0.1875\n",
      "Epoch 116/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9910 - accuracy: 0.6250 - val_loss: 4.3961 - val_accuracy: 0.2708\n",
      "Epoch 117/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9729 - accuracy: 0.6302 - val_loss: 4.5294 - val_accuracy: 0.2708\n",
      "Epoch 118/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0355 - accuracy: 0.6198 - val_loss: 4.7726 - val_accuracy: 0.1458\n",
      "Epoch 119/200\n",
      "192/192 [==============================] - 17s 87ms/step - loss: 1.2678 - accuracy: 0.4948 - val_loss: 4.5314 - val_accuracy: 0.1875\n",
      "Epoch 120/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9241 - accuracy: 0.6406 - val_loss: 4.8750 - val_accuracy: 0.2708\n",
      "Epoch 121/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9002 - accuracy: 0.6615 - val_loss: 4.6624 - val_accuracy: 0.2500\n",
      "Epoch 122/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0293 - accuracy: 0.6042 - val_loss: 4.4014 - val_accuracy: 0.2708\n",
      "Epoch 123/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9093 - accuracy: 0.6510 - val_loss: 4.5223 - val_accuracy: 0.2292\n",
      "Epoch 124/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8986 - accuracy: 0.6458 - val_loss: 4.6487 - val_accuracy: 0.2500\n",
      "Epoch 125/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9592 - accuracy: 0.6354 - val_loss: 3.7454 - val_accuracy: 0.2500\n",
      "Epoch 126/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.9408 - accuracy: 0.6354 - val_loss: 4.1142 - val_accuracy: 0.2708\n",
      "Epoch 127/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8592 - accuracy: 0.6458 - val_loss: 4.4568 - val_accuracy: 0.2500\n",
      "Epoch 128/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8729 - accuracy: 0.6719 - val_loss: 4.6416 - val_accuracy: 0.2500\n",
      "Epoch 129/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8201 - accuracy: 0.6823 - val_loss: 4.9116 - val_accuracy: 0.2500\n",
      "Epoch 130/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.0206 - accuracy: 0.6406 - val_loss: 5.0821 - val_accuracy: 0.2292\n",
      "Epoch 131/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2229 - accuracy: 0.5000 - val_loss: 4.7395 - val_accuracy: 0.2083\n",
      "Epoch 132/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8461 - accuracy: 0.6771 - val_loss: 5.0454 - val_accuracy: 0.2708\n",
      "Epoch 133/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8429 - accuracy: 0.6771 - val_loss: 6.4468 - val_accuracy: 0.2917\n",
      "Epoch 134/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8302 - accuracy: 0.6667 - val_loss: 5.5643 - val_accuracy: 0.2292\n",
      "Epoch 135/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8847 - accuracy: 0.6562 - val_loss: 6.0979 - val_accuracy: 0.2500\n",
      "Epoch 136/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8445 - accuracy: 0.6927 - val_loss: 5.3389 - val_accuracy: 0.2292\n",
      "Epoch 137/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8769 - accuracy: 0.6667 - val_loss: 5.6742 - val_accuracy: 0.2708\n",
      "Epoch 138/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7782 - accuracy: 0.7188 - val_loss: 5.8731 - val_accuracy: 0.2292\n",
      "Epoch 139/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7402 - accuracy: 0.7188 - val_loss: 5.6651 - val_accuracy: 0.2917\n",
      "Epoch 140/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7807 - accuracy: 0.7188 - val_loss: 5.5377 - val_accuracy: 0.1667\n",
      "Epoch 141/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.8808 - accuracy: 0.6458 - val_loss: 5.6761 - val_accuracy: 0.2708\n",
      "Epoch 142/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7533 - accuracy: 0.7448 - val_loss: 5.5969 - val_accuracy: 0.2500\n",
      "Epoch 143/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7808 - accuracy: 0.7188 - val_loss: 5.2541 - val_accuracy: 0.2708\n",
      "Epoch 144/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8069 - accuracy: 0.7031 - val_loss: 5.8690 - val_accuracy: 0.2917\n",
      "Epoch 145/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7580 - accuracy: 0.7031 - val_loss: 5.9595 - val_accuracy: 0.2500\n",
      "Epoch 146/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7011 - accuracy: 0.7448 - val_loss: 6.5279 - val_accuracy: 0.2708\n",
      "Epoch 147/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7404 - accuracy: 0.7396 - val_loss: 6.9493 - val_accuracy: 0.2083\n",
      "Epoch 148/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.0787 - accuracy: 0.5938 - val_loss: 6.1066 - val_accuracy: 0.2083\n",
      "Epoch 149/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7333 - accuracy: 0.7188 - val_loss: 6.9948 - val_accuracy: 0.2500\n",
      "Epoch 150/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7175 - accuracy: 0.7396 - val_loss: 5.5034 - val_accuracy: 0.2708\n",
      "Epoch 151/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7078 - accuracy: 0.7344 - val_loss: 6.1992 - val_accuracy: 0.2500\n",
      "Epoch 152/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6518 - accuracy: 0.7500 - val_loss: 6.7122 - val_accuracy: 0.2500\n",
      "Epoch 153/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6736 - accuracy: 0.7656 - val_loss: 6.9859 - val_accuracy: 0.2083\n",
      "Epoch 154/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9926 - accuracy: 0.6302 - val_loss: 6.6326 - val_accuracy: 0.2292\n",
      "Epoch 155/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6950 - accuracy: 0.7344 - val_loss: 6.2652 - val_accuracy: 0.2500\n",
      "Epoch 156/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6291 - accuracy: 0.7812 - val_loss: 6.2372 - val_accuracy: 0.2917\n",
      "Epoch 157/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7557 - accuracy: 0.7448 - val_loss: 7.1850 - val_accuracy: 0.2500\n",
      "Epoch 158/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9859 - accuracy: 0.6719 - val_loss: 5.0901 - val_accuracy: 0.2500\n",
      "Epoch 159/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7519 - accuracy: 0.7240 - val_loss: 5.2553 - val_accuracy: 0.1875\n",
      "Epoch 160/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7168 - accuracy: 0.7552 - val_loss: 5.2661 - val_accuracy: 0.2500\n",
      "Epoch 161/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6442 - accuracy: 0.7760 - val_loss: 6.4299 - val_accuracy: 0.2500\n",
      "Epoch 162/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.7690 - accuracy: 0.7292 - val_loss: 6.3875 - val_accuracy: 0.2917\n",
      "Epoch 163/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6150 - accuracy: 0.7708 - val_loss: 6.7621 - val_accuracy: 0.2708\n",
      "Epoch 164/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6003 - accuracy: 0.7969 - val_loss: 7.0063 - val_accuracy: 0.2500\n",
      "Epoch 165/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5539 - accuracy: 0.8177 - val_loss: 7.6546 - val_accuracy: 0.2083\n",
      "Epoch 166/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5675 - accuracy: 0.7969 - val_loss: 7.7464 - val_accuracy: 0.2083\n",
      "Epoch 167/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6458 - accuracy: 0.7604 - val_loss: 7.6095 - val_accuracy: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6316 - accuracy: 0.7604 - val_loss: 7.8868 - val_accuracy: 0.2083\n",
      "Epoch 169/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5434 - accuracy: 0.7917 - val_loss: 7.7978 - val_accuracy: 0.2292\n",
      "Epoch 170/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5671 - accuracy: 0.7812 - val_loss: 8.0827 - val_accuracy: 0.2292\n",
      "Epoch 171/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5338 - accuracy: 0.7969 - val_loss: 8.3081 - val_accuracy: 0.2708\n",
      "Epoch 172/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5559 - accuracy: 0.7812 - val_loss: 8.5245 - val_accuracy: 0.2292\n",
      "Epoch 173/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5448 - accuracy: 0.7969 - val_loss: 8.6698 - val_accuracy: 0.2292\n",
      "Epoch 174/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5504 - accuracy: 0.7969 - val_loss: 8.6941 - val_accuracy: 0.2500\n",
      "Epoch 175/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5531 - accuracy: 0.8021 - val_loss: 9.3805 - val_accuracy: 0.2292\n",
      "Epoch 176/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5664 - accuracy: 0.7708 - val_loss: 8.1277 - val_accuracy: 0.2083\n",
      "Epoch 177/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7476 - accuracy: 0.7344 - val_loss: 8.1569 - val_accuracy: 0.2292\n",
      "Epoch 178/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6383 - accuracy: 0.7604 - val_loss: 10.7431 - val_accuracy: 0.2292\n",
      "Epoch 179/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.2463 - accuracy: 0.5781 - val_loss: 6.8473 - val_accuracy: 0.2292\n",
      "Epoch 180/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.8421 - accuracy: 0.6979 - val_loss: 7.0146 - val_accuracy: 0.3125\n",
      "Epoch 181/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6226 - accuracy: 0.7708 - val_loss: 7.6450 - val_accuracy: 0.2500\n",
      "Epoch 182/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.6088 - accuracy: 0.7656 - val_loss: 6.9537 - val_accuracy: 0.3125\n",
      "Epoch 183/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6358 - accuracy: 0.7552 - val_loss: 7.6191 - val_accuracy: 0.1875\n",
      "Epoch 184/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.6263 - accuracy: 0.7865 - val_loss: 7.7950 - val_accuracy: 0.2708\n",
      "Epoch 185/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5625 - accuracy: 0.7812 - val_loss: 7.9560 - val_accuracy: 0.2500\n",
      "Epoch 186/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5365 - accuracy: 0.7969 - val_loss: 7.8950 - val_accuracy: 0.2500\n",
      "Epoch 187/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5746 - accuracy: 0.7865 - val_loss: 9.7460 - val_accuracy: 0.2708\n",
      "Epoch 188/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.7200 - accuracy: 0.7708 - val_loss: 7.0108 - val_accuracy: 0.2292\n",
      "Epoch 189/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5092 - accuracy: 0.8125 - val_loss: 7.3548 - val_accuracy: 0.2292\n",
      "Epoch 190/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5783 - accuracy: 0.7760 - val_loss: 7.8616 - val_accuracy: 0.2500\n",
      "Epoch 191/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5963 - accuracy: 0.7812 - val_loss: 6.5801 - val_accuracy: 0.1875\n",
      "Epoch 192/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9308 - accuracy: 0.6615 - val_loss: 8.1381 - val_accuracy: 0.2083\n",
      "Epoch 193/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.9575 - accuracy: 0.6094 - val_loss: 8.3681 - val_accuracy: 0.2708\n",
      "Epoch 194/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5028 - accuracy: 0.7969 - val_loss: 8.7078 - val_accuracy: 0.2708\n",
      "Epoch 195/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5077 - accuracy: 0.8385 - val_loss: 8.7420 - val_accuracy: 0.2500\n",
      "Epoch 196/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 0.5332 - accuracy: 0.8177 - val_loss: 9.0464 - val_accuracy: 0.2500\n",
      "Epoch 197/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 0.5066 - accuracy: 0.8125 - val_loss: 9.4593 - val_accuracy: 0.2083\n",
      "Epoch 198/200\n",
      "192/192 [==============================] - 16s 82ms/step - loss: 1.2963 - accuracy: 0.6406 - val_loss: 4.9796 - val_accuracy: 0.2083\n",
      "Epoch 199/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.6169 - accuracy: 0.4062 - val_loss: 3.9313 - val_accuracy: 0.2083\n",
      "Epoch 200/200\n",
      "192/192 [==============================] - 16s 81ms/step - loss: 1.5519 - accuracy: 0.4635 - val_loss: 4.2411 - val_accuracy: 0.1875\n",
      "[[3.66845554e-10 8.52956432e-13 8.25367483e-11 ... 4.24137531e-10\n",
      "  4.82414022e-12 2.76540624e-10]\n",
      " [6.84308277e-10 1.35805586e-11 4.59848909e-10 ... 4.43027642e-10\n",
      "  2.23623253e-09 7.20090698e-09]\n",
      " [4.68292523e-11 3.36603693e-15 4.01724530e-12 ... 2.64775960e-14\n",
      "  1.30528734e-14 1.37563173e-11]\n",
      " ...\n",
      " [1.01081608e-03 6.07241120e-04 8.69381649e-04 ... 8.47816118e-04\n",
      "  4.29055130e-04 1.08244643e-03]\n",
      " [1.01081608e-03 6.07241120e-04 8.69381649e-04 ... 8.47816118e-04\n",
      "  4.29055130e-04 1.08244643e-03]\n",
      " [1.01126032e-03 6.05900364e-04 8.66112998e-04 ... 8.45755450e-04\n",
      "  4.29126638e-04 1.08542584e-03]]\n",
      "Test loss: 4.241142590840657\n",
      "Test accuracy: 0.1875\n",
      "[4.241142590840657, 0.1875]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_axis_femur_model('medialSulcus', 2, 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
